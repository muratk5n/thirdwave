# Singularity

There is a lot of talk on this subject: that technology so rising in complexity, with dazzling applications that at one point, some form of AI will surpass human intelligence. This view was exemplified by an early pioneer in robotics research. He said (I paraphrase) "I believe the day will come an AI capable robot will look down to a human as we look down a dog. And I confess, I am rooting for the machines".

Ok. A bit rough but, there it is.

Working with robotics and seeing the algorithms, methods used, I can say that this event in fact is plausible. Technology can get there. Then (let's rationalize all of this) could we perhaps see this AI as an "evolution" of ourselves, that our growth is actually leading us this way? Great, I feel better now. The robot is me! Only better.

But evolution can also go in another direction: in a way that'll result in a human being evolved in such a way that can interface with a computer so efficiently that this 'combination' will never let any kind of singularity event come to fore. Or, make it uncessary.

I believe this is a more likely scenario. We love our tools. Even without a Matrix like plug-in, we get so good interfacing to our tools through our "old-fashioned" "limbs" that some feel whatever tool they use becomes an extension of them. If we can do this, what is stopping us fusing ourselves so well with a computer that can do all heavy lifting while we concentrate on more "human" tasks? This interfacing ability would get inherited and 'chosen' through successive evoution and become stronger, more effective.

So I am not 'scared' in any way. Just the fact that we are talking about this today will assure it happening less likely. Sure some crazy scientist can work on a T-4000000 complete with an Austrian accent and let it loose on humans, but this all comes back to MAD rationale again. Why use a technology when in some day it might come back and bite you in the ass? I don't think so.

We are safe. Sleep soundly humans.
