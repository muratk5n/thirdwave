
Pinned Post

<img width='340' src='https://cdn.fosstodon.org/media_attachments/files/113/740/005/109/659/968/original/4a44ec0290bf2c04.png'/>

---

This is the way

CNBC: "Spain plans to tackle housing crisis with 100% tax on homes
bought by foreigners"

---

Politico: "A top progressive group [Justice Democrats] has a plan to
forge a way forward after Democrats' brutal election cycle: a renewed
push to primary members of its own party... 'There is something wrong
with this party as a whole right now,' [said a spox], 'and it’s time
to clean up shop in this Democratic Party.. The 2024 election showed
that the party establishment didn’t learn its lessons'.. And
Democratic members coming into this Congress should be on notice:
'Their primary starts now... Voters want to see a Democratic Party
that is serious about taking on the wealthy elite and getting big
money out of politics, not parade around billionaires as campaign
surrogates'"

---

The example works, strange combination of AND, OR and bitshift
operator plus a recursion. It does look like the type of code that
could be built up from simpler components, during a program search.

```python
addition(123,345)
```

```text
Out[1]: 468
```

---

FC claims AGI needs to learn programs rather than representations
memorized out of words via brute force. It should be possible to learn
a program like below, not the usual algorithm for addition, after
seeing few examples of addition. 

---

Chollet: "Here for instance, our model of addition is an algorithm
expressed in terms of binary operators.

```python
def addition(x,y):
   if y == 0: return x
   return addition(x^y, (x&y) << 1)
```

A model of this kind will generalize strongly. It will be able to
return the right answer. The exactly right answer. For any input at
all even inputs very far from the distribution of inputs that your
agent may have seen before. That is strong abstraction. This is where
LLMs still fall short"

---

Francois Chollet: "There's been lots of talk about how LLMs perform 'in-context
learning' to adapt to new problems. But what seems to actually happen
is that LLMs are fetching memorized programs that map to the current
prompt.

If they don't have a memorized program ready – if they're faced with
something slightly unfamiliar, no matter how simple – they will
fail. Even when the novelty comes in the form of a small variation of
a problem they did memorize.

[[-]](https://arcprize.org/blog/beat-arc-agi-deep-learning-and-program-synthesis)

---

Zucman, *The Triumph of Injustice*: "FDR’s strategy worked as long as
successive administrations upheld the New Deal–era belief system. That
changed in the early 1980s. 'Government is not the solution to our
problem; government is the problem,' Reagan famously said in his
inaugural address of January 1981. If some people were tempted to
eschew taxation, they were not to blame: high, 'un-American' tax rates
were.  In the new ideology that swept through the United States in the
early 1980s, dodging taxes became the patriotic thing to do. Since
'taxation was theft,' according to the revived libertarian creed, it
was also the moral thing to do.  Until the 1970s, successive
administrations had fought the tax-avoidance industry. When Reagan
entered the White House in 1981, the industry became
government-approved. The tax-sheltering frenzy could start.

And *frenzy* doesn’t begin to capture the scale of what happened. The
industry mushroomed. A network of financial entrepreneurs, promoters,
and advisers stormed the market. Some of these inventors required
their staffers to come up with one new idea a week. They brimmed
with creativity and produced groundbreaking tax dodges. Whenever the
IRS shut down a particularly egregious scheme, several others would
spawn"

---

Libération: "François Bayrou's future rests on one word: 'Suspension.'
The socialists, who have been negotiating with the government for a
week to rebalance the budget, want to hear it pronounced by the Prime
Minister during his general policy statement (DPG) this afternoon in
the Assembly. 'Regardless of the concessions elsewhere, the media
debate is currently focused on pensions, we will not give up ,' warns
a socialist executive. At the end of last week, the socialist
negotiators at least stated an 'agreement of views' on local
authorities, housing and even overseas territories. A tax on wealth is
also under consideration, inspired by the economist Gabriel
Zucman. 'Lombard is giving us signals, he wants to give us the
possibility of not censoring,' says the same socialist. But he also
tells us that in the end, 'it is Bayrou who will decide. If he commits
to suspending the pension reform, we will not vote for the motion of
censure, even if we are the only ones on the left'"

---

## Reference

[Nations and Nationalism, Culture, Narratives](0119/2013/02/nations-and-nationalism.html)

[The Fundamentals of Industrial Ideologies](0119/2011/04/fundamentals-of-industrial-ideologies.html)

[Education, Workplace](0119/2017/09/education-workplace.html)

[Science and Technology](0119/2018/09/science-technology.html)

[Democracy, Parties](0119/2016/11/democracy.html)

[Economy](2021/01/economy.html)

[Globalization](0119/2018/09/globalization.html)

[Rome, The First Wave, Religion](0119/2017/12/rome.html)

[Human Nature & Health](2020/07/human-nature.html)

[Climate Change](2022/01/climate.html)

[Reports](2021/01/reports.html)

[The Middle East](0119/2019/07/middleeast.html)

[Games](2024/06/games.html)

[TR](../tr/index.html)

## Browse

[Members, Donations](2022/08/members.html)

[By Year](years.html)

[Search](https://muratk5n.github.io/thirdwave/en/search.html)

[Microblog Archive](mbl/index.html)

[PDF](https://www.dropbox.com/scl/fi/8kl0sla1booo83zeb28dn/tw-all.pdf?rlkey=p9r319p8jbzak5du3dasju05y&st=28wknfsp&raw=1)

Also on 
[Mastodon](https://fosstodon.org/@muratk5n),
[Codeberg](https://muratk5n.codeberg.page/en/),
[Github Pages](https://muratk5n.github.io/thirdwave/en/)



